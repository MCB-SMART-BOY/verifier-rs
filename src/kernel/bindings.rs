// SPDX-License-Identifier: GPL-2.0

// Allow non_camel_case_types for C-compatible bindings
#![allow(non_camel_case_types)]
// Allow missing docs for bindings - they mirror kernel definitions
#![allow(missing_docs)]

//! FFI bindings to kernel BPF data structures.
//!
//! These bindings mirror the C structures defined in:
//! - `include/linux/bpf.h`
//! - `include/linux/bpf_verifier.h`
//! - `include/uapi/linux/bpf.h`
//! - `include/linux/btf.h`
//!
//! # Kernel Integration
//!
//! In a real kernel build, these would be auto-generated by `bindgen`
//! from the kernel headers. This file provides the structure definitions
//! needed for the Rust verifier to interface with kernel code.
//!
//! When integrated into the kernel build system, replace this with:
//! ```ignore
//! use kernel::bindings::*;
//! ```

// ============================================================================
// Constants from include/uapi/linux/bpf.h
// ============================================================================

/// Maximum number of BPF registers
pub const MAX_BPF_REG: usize = 11;

/// BPF register numbers
pub const BPF_REG_0: u32 = 0;
pub const BPF_REG_1: u32 = 1;
pub const BPF_REG_2: u32 = 2;
pub const BPF_REG_3: u32 = 3;
pub const BPF_REG_4: u32 = 4;
pub const BPF_REG_5: u32 = 5;
pub const BPF_REG_6: u32 = 6;
pub const BPF_REG_7: u32 = 7;
pub const BPF_REG_8: u32 = 8;
pub const BPF_REG_9: u32 = 9;
pub const BPF_REG_10: u32 = 10; // Frame pointer (read-only)

/// Maximum BPF stack size
pub const MAX_BPF_STACK: u32 = 512;

/// Maximum number of subprograms
pub const MAX_BPF_SUBPROGS: usize = 256;

/// Maximum call depth
pub const MAX_CALL_FRAMES: u32 = 8;

/// Maximum number of instructions (privileged)
pub const BPF_COMPLEXITY_LIMIT_INSNS: u32 = 1_000_000;

/// Maximum number of instructions (unprivileged)
pub const BPF_MAXINSNS: u32 = 4096;

/// Maximum number of states for state pruning
pub const BPF_COMPLEXITY_LIMIT_STATES: u32 = 64;

/// Maximum jump sequence complexity
pub const BPF_COMPLEXITY_LIMIT_JMP_SEQ: u32 = 8192;

/// Map key poison marker
pub const BPF_MAP_KEY_POISON: u64 = 1 << 63;

/// Map key seen marker
pub const BPF_MAP_KEY_SEEN: u64 = 1 << 62;

/// Maximum size for global percpu memory allocator
pub const BPF_GLOBAL_PERCPU_MA_MAX_SIZE: usize = 512;

/// Minimum size for private stack
pub const BPF_PRIV_STACK_MIN_SIZE: usize = 64;

/// Maximum log buffer size
pub const BPF_MAX_LOG_BUF: u32 = 1 << 24; // 16 MB

/// Maximum BTF types
pub const MAX_USED_BTFS: usize = 64;

/// Maximum tail call count
pub const MAX_TAIL_CALL_CNT: u32 = 33;

/// Maximum may_goto depth
pub const MAX_MAY_GOTO_DEPTH: u32 = 8;

// ============================================================================
// BPF instruction encoding
// ============================================================================

/// BPF instruction classes
pub const BPF_LD: u8 = 0x00;
pub const BPF_LDX: u8 = 0x01;
pub const BPF_ST: u8 = 0x02;
pub const BPF_STX: u8 = 0x03;
pub const BPF_ALU: u8 = 0x04;
pub const BPF_JMP: u8 = 0x05;
pub const BPF_JMP32: u8 = 0x06;
pub const BPF_ALU64: u8 = 0x07;

/// BPF ALU operations
pub const BPF_ADD: u8 = 0x00;
pub const BPF_SUB: u8 = 0x10;
pub const BPF_MUL: u8 = 0x20;
pub const BPF_DIV: u8 = 0x30;
pub const BPF_OR: u8 = 0x40;
pub const BPF_AND: u8 = 0x50;
pub const BPF_LSH: u8 = 0x60;
pub const BPF_RSH: u8 = 0x70;
pub const BPF_NEG: u8 = 0x80;
pub const BPF_MOD: u8 = 0x90;
pub const BPF_XOR: u8 = 0xa0;
pub const BPF_MOV: u8 = 0xb0;
pub const BPF_ARSH: u8 = 0xc0;
pub const BPF_END: u8 = 0xd0;

/// BPF signed division (sdiv/smod)
pub const BPF_SDIV: u8 = 0xe0;
pub const BPF_SMOD: u8 = 0xf0;

/// BPF jump operations
pub const BPF_JA: u8 = 0x00;
pub const BPF_JEQ: u8 = 0x10;
pub const BPF_JGT: u8 = 0x20;
pub const BPF_JGE: u8 = 0x30;
pub const BPF_JSET: u8 = 0x40;
pub const BPF_JNE: u8 = 0x50;
pub const BPF_JSGT: u8 = 0x60;
pub const BPF_JSGE: u8 = 0x70;
pub const BPF_CALL: u8 = 0x80;
pub const BPF_EXIT: u8 = 0x90;
pub const BPF_JLT: u8 = 0xa0;
pub const BPF_JLE: u8 = 0xb0;
pub const BPF_JSLT: u8 = 0xc0;
pub const BPF_JSLE: u8 = 0xd0;

/// BPF source operand
pub const BPF_K: u8 = 0x00;
pub const BPF_X: u8 = 0x08;

/// BPF memory sizes
pub const BPF_W: u8 = 0x00;  // 32-bit
pub const BPF_H: u8 = 0x08;  // 16-bit
pub const BPF_B: u8 = 0x10;  // 8-bit
pub const BPF_DW: u8 = 0x18; // 64-bit

/// BPF memory modes
pub const BPF_IMM: u8 = 0x00;
pub const BPF_ABS: u8 = 0x20;
pub const BPF_IND: u8 = 0x40;
pub const BPF_MEM: u8 = 0x60;
pub const BPF_MEMSX: u8 = 0x80;
pub const BPF_ATOMIC: u8 = 0xc0;

/// Atomic operations
pub const BPF_ATOMIC_ADD: i32 = 0x00;
pub const BPF_ATOMIC_OR: i32 = 0x40;
pub const BPF_ATOMIC_AND: i32 = 0x50;
pub const BPF_ATOMIC_XOR: i32 = 0xa0;
pub const BPF_XCHG: i32 = 0xe1;
pub const BPF_CMPXCHG: i32 = 0xf1;
pub const BPF_FETCH: i32 = 0x01;

/// Pseudo source register values for CALL
pub const BPF_PSEUDO_CALL: u8 = 1;
pub const BPF_PSEUDO_KFUNC_CALL: u8 = 2;

/// Pseudo source register values for LD_IMM64
pub const BPF_PSEUDO_MAP_FD: u8 = 1;
pub const BPF_PSEUDO_MAP_VALUE: u8 = 2;
pub const BPF_PSEUDO_BTF_ID: u8 = 3;
pub const BPF_PSEUDO_FUNC: u8 = 4;
pub const BPF_PSEUDO_MAP_IDX: u8 = 5;
pub const BPF_PSEUDO_MAP_IDX_VALUE: u8 = 6;

/// Endian conversion
pub const BPF_TO_LE: u8 = 0x00;
pub const BPF_TO_BE: u8 = 0x08;

// ============================================================================
// BTF Constants
// ============================================================================

/// BTF magic number
pub const BTF_MAGIC: u16 = 0xEB9F;

/// BTF type kinds
pub const BTF_KIND_UNKN: u32 = 0;
pub const BTF_KIND_INT: u32 = 1;
pub const BTF_KIND_PTR: u32 = 2;
pub const BTF_KIND_ARRAY: u32 = 3;
pub const BTF_KIND_STRUCT: u32 = 4;
pub const BTF_KIND_UNION: u32 = 5;
pub const BTF_KIND_ENUM: u32 = 6;
pub const BTF_KIND_FWD: u32 = 7;
pub const BTF_KIND_TYPEDEF: u32 = 8;
pub const BTF_KIND_VOLATILE: u32 = 9;
pub const BTF_KIND_CONST: u32 = 10;
pub const BTF_KIND_RESTRICT: u32 = 11;
pub const BTF_KIND_FUNC: u32 = 12;
pub const BTF_KIND_FUNC_PROTO: u32 = 13;
pub const BTF_KIND_VAR: u32 = 14;
pub const BTF_KIND_DATASEC: u32 = 15;
pub const BTF_KIND_FLOAT: u32 = 16;
pub const BTF_KIND_DECL_TAG: u32 = 17;
pub const BTF_KIND_TYPE_TAG: u32 = 18;
pub const BTF_KIND_ENUM64: u32 = 19;
pub const BTF_KIND_MAX: u32 = BTF_KIND_ENUM64;

/// BTF function linkage
pub const BTF_FUNC_STATIC: u32 = 0;
pub const BTF_FUNC_GLOBAL: u32 = 1;
pub const BTF_FUNC_EXTERN: u32 = 2;

/// BTF integer encoding
pub const BTF_INT_SIGNED: u32 = 1 << 0;
pub const BTF_INT_CHAR: u32 = 1 << 1;
pub const BTF_INT_BOOL: u32 = 1 << 2;

// ============================================================================
// Kfunc flags
// ============================================================================

/// Kfunc flags from include/linux/btf.h
pub const KF_ACQUIRE: u32 = 1 << 0;
pub const KF_RELEASE: u32 = 1 << 1;
pub const KF_RET_NULL: u32 = 1 << 2;
pub const KF_KPTR_GET: u32 = 1 << 3;
pub const KF_DESTRUCTIVE: u32 = 1 << 4;
pub const KF_SLEEPABLE: u32 = 1 << 5;
pub const KF_TRUSTED_ARGS: u32 = 1 << 6;
pub const KF_RCU: u32 = 1 << 7;
pub const KF_ITER_NEW: u32 = 1 << 8;
pub const KF_ITER_NEXT: u32 = 1 << 9;
pub const KF_ITER_DESTROY: u32 = 1 << 10;
pub const KF_RCU_PROTECTED: u32 = 1 << 11;

// ============================================================================
// Type flags from bpf.h
// ============================================================================

/// Type modifier flags for bpf_reg_type
pub const PTR_MAYBE_NULL: u32 = 1 << 8;
pub const MEM_RDONLY: u32 = 1 << 9;
pub const MEM_RINGBUF: u32 = 1 << 10;
pub const MEM_USER: u32 = 1 << 11;
pub const MEM_PERCPU: u32 = 1 << 12;
pub const OBJ_RELEASE: u32 = 1 << 13;
pub const PTR_UNTRUSTED: u32 = 1 << 14;
pub const MEM_UNINIT: u32 = 1 << 15;
pub const DYNPTR_TYPE_LOCAL: u32 = 1 << 16;
pub const DYNPTR_TYPE_RINGBUF: u32 = 1 << 17;
pub const MEM_FIXED_SIZE: u32 = 1 << 18;
pub const MEM_ALLOC: u32 = 1 << 19;
pub const PTR_TRUSTED: u32 = 1 << 20;
pub const MEM_RCU: u32 = 1 << 21;
pub const NON_OWN_REF: u32 = 1 << 22;
pub const DYNPTR_TYPE_SKB: u32 = 1 << 23;
pub const DYNPTR_TYPE_XDP: u32 = 1 << 24;

// ============================================================================
// Core BPF structures
// ============================================================================

/// BPF instruction (8 bytes, matches kernel struct bpf_insn)
#[repr(C)]
#[derive(Debug, Clone, Copy, Default, PartialEq, Eq)]
pub struct bpf_insn {
    /// Opcode: class | operation | source
    pub code: u8,
    /// Destination register (low 4 bits) and source register (high 4 bits)
    pub dst_src_reg: u8,
    /// Signed offset for jumps/memory access
    pub off: i16,
    /// Immediate value
    pub imm: i32,
}

impl bpf_insn {
    /// Get destination register number
    #[inline]
    pub const fn dst_reg(&self) -> u8 {
        self.dst_src_reg & 0x0f
    }

    /// Get source register number
    #[inline]
    pub const fn src_reg(&self) -> u8 {
        (self.dst_src_reg >> 4) & 0x0f
    }

    /// Get instruction class
    #[inline]
    pub const fn class(&self) -> u8 {
        self.code & 0x07
    }

    /// Get instruction size
    #[inline]
    pub const fn size(&self) -> u8 {
        (self.code >> 3) & 0x03
    }

    /// Get instruction mode
    #[inline]
    pub const fn mode(&self) -> u8 {
        self.code & 0xe0
    }

    /// Check if this is a 64-bit ALU instruction
    #[inline]
    pub const fn is_alu64(&self) -> bool {
        self.class() == BPF_ALU64
    }

    /// Check if this is a jump instruction
    #[inline]
    pub const fn is_jmp(&self) -> bool {
        let class = self.class();
        class == BPF_JMP || class == BPF_JMP32
    }

    /// Check if this is a helper call
    #[inline]
    pub const fn is_helper_call(&self) -> bool {
        self.code == (BPF_JMP | BPF_CALL) && self.src_reg() == 0
    }

    /// Check if this is a pseudo call
    #[inline]
    pub const fn is_pseudo_call(&self) -> bool {
        self.code == (BPF_JMP | BPF_CALL) && self.src_reg() == BPF_PSEUDO_CALL
    }

    /// Check if this is a kfunc call
    #[inline]
    pub const fn is_kfunc_call(&self) -> bool {
        self.code == (BPF_JMP | BPF_CALL) && self.src_reg() == BPF_PSEUDO_KFUNC_CALL
    }
}

/// BPF program types (from enum bpf_prog_type)
#[repr(u32)]
#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
#[expect(non_camel_case_types, reason = "Matches kernel C type naming convention")]
pub enum bpf_prog_type {
    #[default]
    BPF_PROG_TYPE_UNSPEC = 0,
    BPF_PROG_TYPE_SOCKET_FILTER = 1,
    BPF_PROG_TYPE_KPROBE = 2,
    BPF_PROG_TYPE_SCHED_CLS = 3,
    BPF_PROG_TYPE_SCHED_ACT = 4,
    BPF_PROG_TYPE_TRACEPOINT = 5,
    BPF_PROG_TYPE_XDP = 6,
    BPF_PROG_TYPE_PERF_EVENT = 7,
    BPF_PROG_TYPE_CGROUP_SKB = 8,
    BPF_PROG_TYPE_CGROUP_SOCK = 9,
    BPF_PROG_TYPE_LWT_IN = 10,
    BPF_PROG_TYPE_LWT_OUT = 11,
    BPF_PROG_TYPE_LWT_XMIT = 12,
    BPF_PROG_TYPE_SOCK_OPS = 13,
    BPF_PROG_TYPE_SK_SKB = 14,
    BPF_PROG_TYPE_CGROUP_DEVICE = 15,
    BPF_PROG_TYPE_SK_MSG = 16,
    BPF_PROG_TYPE_RAW_TRACEPOINT = 17,
    BPF_PROG_TYPE_CGROUP_SOCK_ADDR = 18,
    BPF_PROG_TYPE_LWT_SEG6LOCAL = 19,
    BPF_PROG_TYPE_LIRC_MODE2 = 20,
    BPF_PROG_TYPE_SK_REUSEPORT = 21,
    BPF_PROG_TYPE_FLOW_DISSECTOR = 22,
    BPF_PROG_TYPE_CGROUP_SYSCTL = 23,
    BPF_PROG_TYPE_RAW_TRACEPOINT_WRITABLE = 24,
    BPF_PROG_TYPE_CGROUP_SOCKOPT = 25,
    BPF_PROG_TYPE_TRACING = 26,
    BPF_PROG_TYPE_STRUCT_OPS = 27,
    BPF_PROG_TYPE_EXT = 28,
    BPF_PROG_TYPE_LSM = 29,
    BPF_PROG_TYPE_SK_LOOKUP = 30,
    BPF_PROG_TYPE_SYSCALL = 31,
    BPF_PROG_TYPE_NETFILTER = 32,
}

/// BPF attach types (from enum bpf_attach_type)
#[repr(u32)]
#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
#[expect(non_camel_case_types, reason = "Matches kernel C type naming convention")]
pub enum bpf_attach_type {
    #[default]
    BPF_CGROUP_INET_INGRESS = 0,
    BPF_CGROUP_INET_EGRESS = 1,
    BPF_CGROUP_INET_SOCK_CREATE = 2,
    BPF_CGROUP_SOCK_OPS = 3,
    BPF_SK_SKB_STREAM_PARSER = 4,
    BPF_SK_SKB_STREAM_VERDICT = 5,
    BPF_CGROUP_DEVICE = 6,
    BPF_SK_MSG_VERDICT = 7,
    BPF_CGROUP_INET4_BIND = 8,
    BPF_CGROUP_INET6_BIND = 9,
    BPF_CGROUP_INET4_CONNECT = 10,
    BPF_CGROUP_INET6_CONNECT = 11,
    BPF_CGROUP_INET4_POST_BIND = 12,
    BPF_CGROUP_INET6_POST_BIND = 13,
    BPF_CGROUP_UDP4_SENDMSG = 14,
    BPF_CGROUP_UDP6_SENDMSG = 15,
    BPF_LIRC_MODE2 = 16,
    BPF_FLOW_DISSECTOR = 17,
    BPF_CGROUP_SYSCTL = 18,
    BPF_CGROUP_UDP4_RECVMSG = 19,
    BPF_CGROUP_UDP6_RECVMSG = 20,
    BPF_CGROUP_GETSOCKOPT = 21,
    BPF_CGROUP_SETSOCKOPT = 22,
    BPF_TRACE_RAW_TP = 23,
    BPF_TRACE_FENTRY = 24,
    BPF_TRACE_FEXIT = 25,
    BPF_MODIFY_RETURN = 26,
    BPF_LSM_MAC = 27,
    BPF_TRACE_ITER = 28,
    BPF_CGROUP_INET4_GETPEERNAME = 29,
    BPF_CGROUP_INET6_GETPEERNAME = 30,
    BPF_CGROUP_INET4_GETSOCKNAME = 31,
    BPF_CGROUP_INET6_GETSOCKNAME = 32,
    BPF_XDP_DEVMAP = 33,
    BPF_CGROUP_INET_SOCK_RELEASE = 34,
    BPF_XDP_CPUMAP = 35,
    BPF_SK_LOOKUP = 36,
    BPF_XDP = 37,
    BPF_SK_SKB_VERDICT = 38,
    BPF_SK_REUSEPORT_SELECT = 39,
    BPF_SK_REUSEPORT_SELECT_OR_MIGRATE = 40,
    BPF_PERF_EVENT = 41,
    BPF_TRACE_KPROBE_MULTI = 42,
    BPF_LSM_CGROUP = 43,
    BPF_STRUCT_OPS = 44,
    BPF_NETFILTER = 45,
    BPF_TCX_INGRESS = 46,
    BPF_TCX_EGRESS = 47,
    BPF_TRACE_UPROBE_MULTI = 48,
    BPF_CGROUP_UNIX_CONNECT = 49,
    BPF_CGROUP_UNIX_SENDMSG = 50,
    BPF_CGROUP_UNIX_RECVMSG = 51,
    BPF_CGROUP_UNIX_GETPEERNAME = 52,
    BPF_CGROUP_UNIX_GETSOCKNAME = 53,
    BPF_NETKIT_PRIMARY = 54,
    BPF_NETKIT_PEER = 55,
}

/// BPF map types (from enum bpf_map_type)
#[repr(u32)]
#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
#[expect(non_camel_case_types, reason = "Matches kernel C type naming convention")]
pub enum bpf_map_type {
    #[default]
    BPF_MAP_TYPE_UNSPEC = 0,
    BPF_MAP_TYPE_HASH = 1,
    BPF_MAP_TYPE_ARRAY = 2,
    BPF_MAP_TYPE_PROG_ARRAY = 3,
    BPF_MAP_TYPE_PERF_EVENT_ARRAY = 4,
    BPF_MAP_TYPE_PERCPU_HASH = 5,
    BPF_MAP_TYPE_PERCPU_ARRAY = 6,
    BPF_MAP_TYPE_STACK_TRACE = 7,
    BPF_MAP_TYPE_CGROUP_ARRAY = 8,
    BPF_MAP_TYPE_LRU_HASH = 9,
    BPF_MAP_TYPE_LRU_PERCPU_HASH = 10,
    BPF_MAP_TYPE_LPM_TRIE = 11,
    BPF_MAP_TYPE_ARRAY_OF_MAPS = 12,
    BPF_MAP_TYPE_HASH_OF_MAPS = 13,
    BPF_MAP_TYPE_DEVMAP = 14,
    BPF_MAP_TYPE_SOCKMAP = 15,
    BPF_MAP_TYPE_CPUMAP = 16,
    BPF_MAP_TYPE_XSKMAP = 17,
    BPF_MAP_TYPE_SOCKHASH = 18,
    BPF_MAP_TYPE_CGROUP_STORAGE = 19,
    BPF_MAP_TYPE_REUSEPORT_SOCKARRAY = 20,
    BPF_MAP_TYPE_PERCPU_CGROUP_STORAGE = 21,
    BPF_MAP_TYPE_QUEUE = 22,
    BPF_MAP_TYPE_STACK = 23,
    BPF_MAP_TYPE_SK_STORAGE = 24,
    BPF_MAP_TYPE_DEVMAP_HASH = 25,
    BPF_MAP_TYPE_STRUCT_OPS = 26,
    BPF_MAP_TYPE_RINGBUF = 27,
    BPF_MAP_TYPE_INODE_STORAGE = 28,
    BPF_MAP_TYPE_TASK_STORAGE = 29,
    BPF_MAP_TYPE_BLOOM_FILTER = 30,
    BPF_MAP_TYPE_USER_RINGBUF = 31,
    BPF_MAP_TYPE_CGRP_STORAGE = 32,
    BPF_MAP_TYPE_ARENA = 33,
}

/// BPF register types for verifier state tracking
#[repr(u32)]
#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
#[expect(non_camel_case_types, reason = "Matches kernel C type naming convention")]
pub enum bpf_reg_type {
    #[default]
    NOT_INIT = 0,
    SCALAR_VALUE = 1,
    PTR_TO_CTX = 2,
    CONST_PTR_TO_MAP = 3,
    PTR_TO_MAP_VALUE = 4,
    PTR_TO_MAP_KEY = 5,
    PTR_TO_STACK = 6,
    PTR_TO_PACKET_META = 7,
    PTR_TO_PACKET = 8,
    PTR_TO_PACKET_END = 9,
    PTR_TO_FLOW_KEYS = 10,
    PTR_TO_SOCKET = 11,
    PTR_TO_SOCK_COMMON = 12,
    PTR_TO_TCP_SOCK = 13,
    PTR_TO_TP_BUFFER = 14,
    PTR_TO_XDP_SOCK = 15,
    PTR_TO_BTF_ID = 16,
    PTR_TO_MEM = 17,
    PTR_TO_ARENA = 18,
    PTR_TO_BUF = 19,
    PTR_TO_FUNC = 20,
    CONST_PTR_TO_DYNPTR = 21,
}

/// Subprogram information
#[repr(C)]
#[derive(Debug, Clone, Default)]
pub struct bpf_subprog_info {
    /// Start instruction index
    pub start: u32,
    /// End instruction index
    pub end: u32,
    /// Line info index
    pub linfo_idx: u32,
    /// Stack depth
    pub stack_depth: u16,
    /// Whether it has tail call
    pub has_tail_call: bool,
    /// Whether it has ld_abs/ld_ind
    pub has_ld_abs: bool,
    /// Whether it's an async callback
    pub is_async_cb: bool,
    /// Whether it's an exception callback
    pub is_exception_cb: bool,
    /// Whether it's a callback
    pub is_cb: bool,
    /// Arguments count
    pub arg_cnt: u8,
    /// BTF function ID
    pub btf_id: u32,
}

/// BPF program structure (simplified)
#[repr(C)]
pub struct bpf_prog {
    /// Program type
    pub prog_type: bpf_prog_type,
    /// Expected attach type
    pub expected_attach_type: bpf_attach_type,
    /// Number of instructions
    pub len: u32,
    /// JIT'ed image length
    pub jited_len: u32,
    /// Tag for identification
    pub tag: [u8; 8],
    /// Lock protect
    pub lock: u64,
    /// Instructions array (flexible array member)
    pub insns: *const bpf_insn,
    /// Auxiliary data
    pub aux: *mut bpf_prog_aux,
}

/// BPF program auxiliary data
#[repr(C)]
pub struct bpf_prog_aux {
    /// Attach BTF ID for tracing
    pub attach_btf_id: u32,
    /// Attach function name length
    pub attach_func_name_len: u32,
    /// Number of subprograms
    pub func_cnt: u32,
    /// Exception callback index
    pub exception_cb_idx: u32,
    /// Subprogram information array
    pub func_info: *mut bpf_func_info,
    /// Subprogram info count
    pub func_info_cnt: u32,
    /// Subprogram auxiliary info
    pub func_info_aux: *mut bpf_func_info_aux,
    /// BTF for this program
    pub btf: *mut btf,
    /// Attach BTF
    pub attach_btf: *mut btf,
    /// Attach function proto
    pub attach_func_proto: *const btf_type,
    /// Attach function name
    pub attach_func_name: *const core::ffi::c_char,
    /// Subprogram info
    pub sub: *mut bpf_subprog_info,
    /// Program name
    pub name: [u8; 16],
    /// Whether program is privileged
    pub cap_sys_admin: bool,
    /// Whether program is sleepable
    pub sleepable: bool,
    /// Verified instruction count
    pub verified_insns: u32,
    /// Number of cgroup storage maps
    pub cgroup_storage_cnt: u32,
    /// Whether uses BPF LSM
    pub lsm_hook_idx: i32,
}

/// BPF function info
#[repr(C)]
#[derive(Debug, Clone, Default)]
pub struct bpf_func_info {
    /// Instruction offset
    pub insn_off: u32,
    /// BTF type ID
    pub type_id: u32,
}

/// BPF function info auxiliary
#[repr(C)]
#[derive(Debug, Clone, Default)]
pub struct bpf_func_info_aux {
    /// Linkage (static, global, extern)
    pub linkage: u32,
    /// Whether is unreliable
    pub unreliable: bool,
}

/// BTF header
#[repr(C)]
#[derive(Debug, Clone, Default)]
pub struct btf_header {
    /// Magic number
    pub magic: u16,
    /// Version
    pub version: u8,
    /// Flags
    pub flags: u8,
    /// Header length
    pub hdr_len: u32,
    /// Type section offset
    pub type_off: u32,
    /// Type section length
    pub type_len: u32,
    /// String section offset
    pub str_off: u32,
    /// String section length
    pub str_len: u32,
}

/// BTF type structure
#[repr(C)]
#[derive(Debug, Clone, Default)]
pub struct btf_type {
    /// Name offset
    pub name_off: u32,
    /// Info (kind, vlen, kflag)
    pub info: u32,
    /// Size or type depending on kind
    pub size_or_type: u32,
}

impl btf_type {
    /// Get kind from info
    #[inline]
    pub const fn kind(&self) -> u32 {
        (self.info >> 24) & 0x1f
    }

    /// Get vlen from info
    #[inline]
    pub const fn vlen(&self) -> u32 {
        self.info & 0xffff
    }

    /// Get kflag from info
    #[inline]
    pub const fn kflag(&self) -> bool {
        (self.info >> 31) != 0
    }
}

/// BTF structure placeholder
#[repr(C)]
pub struct btf {
    /// Data pointer (opaque)
    pub data: *const core::ffi::c_void,
    /// Types array
    pub types: *const *const btf_type,
    /// Number of types
    pub nr_types: u32,
    /// Resolved types
    pub resolved_ids: *const u32,
    /// String section
    pub strings: *const core::ffi::c_char,
}

/// BPF map structure
#[repr(C)]
pub struct bpf_map {
    /// Map operations
    pub ops: *const bpf_map_ops,
    /// Inner map (for map-in-map)
    pub inner_map_meta: *mut bpf_map,
    /// Map type
    pub map_type: bpf_map_type,
    /// Key size in bytes
    pub key_size: u32,
    /// Value size in bytes
    pub value_size: u32,
    /// Maximum entries
    pub max_entries: u32,
    /// Extra bytes for map value
    pub map_extra: u64,
    /// Map flags
    pub map_flags: u32,
    /// Spin lock offset
    pub spin_lock_off: i32,
    /// RES spin lock offset
    pub res_spin_lock_off: i32,
    /// Timer offset
    pub timer_off: i32,
    /// Work queue offset
    pub wq_off: i32,
    /// Map name
    pub name: [u8; 16],
    /// BTF key type ID
    pub btf_key_type_id: u32,
    /// BTF value type ID
    pub btf_value_type_id: u32,
    /// BTF vmlinux value type ID
    pub btf_vmlinux_value_type_id: u32,
    /// BTF for this map
    pub btf: *mut btf,
    /// BTF record
    pub record: *mut btf_record,
}

/// BPF map operations
#[repr(C)]
pub struct bpf_map_ops {
    /// Map allocation size
    pub map_alloc_check: Option<unsafe extern "C" fn(attr: *mut bpf_attr) -> i32>,
    /// Map allocation
    pub map_alloc: Option<unsafe extern "C" fn(attr: *mut bpf_attr) -> *mut bpf_map>,
    /// Map release
    pub map_release: Option<unsafe extern "C" fn(map: *mut bpf_map, file: *mut core::ffi::c_void)>,
    /// Map free
    pub map_free: Option<unsafe extern "C" fn(map: *mut bpf_map)>,
    // ... more ops
}

/// BTF field type
#[repr(u32)]
#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub enum btf_field_type {
    #[default]
    BPF_SPIN_LOCK = 1 << 0,
    BPF_TIMER = 1 << 1,
    BPF_KPTR_UNREF = 1 << 2,
    BPF_KPTR_REF = 1 << 3,
    BPF_LIST_HEAD = 1 << 4,
    BPF_LIST_NODE = 1 << 5,
    BPF_RB_ROOT = 1 << 6,
    BPF_RB_NODE = 1 << 7,
    BPF_GRAPH_NODE_OR_ROOT = 1 << 8,
    BPF_REFCOUNT = 1 << 9,
    BPF_WORKQUEUE = 1 << 10,
    BPF_RES_SPIN_LOCK = 1 << 11,
}

/// BTF field
#[repr(C)]
#[derive(Debug, Clone, Default)]
pub struct btf_field {
    /// Offset in value
    pub offset: u32,
    /// Field size
    pub size: u32,
    /// Field type
    pub type_: btf_field_type,
}

/// BTF record
#[repr(C)]
pub struct btf_record {
    /// Number of fields
    pub cnt: u32,
    /// Field mask
    pub field_mask: u32,
    /// Spin lock offset
    pub spin_lock_off: i32,
    /// Timer offset
    pub timer_off: i32,
    /// Work queue offset
    pub wq_off: i32,
    /// Refcount offset
    pub refcount_off: i32,
    /// Fields array
    pub fields: [btf_field; 0], // Flexible array
}

/// BPF attribute union for syscall
#[repr(C)]
pub union bpf_attr {
    /// Program load attributes
    pub prog_load: core::mem::ManuallyDrop<bpf_attr_prog_load>,
    /// Generic bytes
    pub bytes: [u8; 128],
}

/// Program load attributes
#[repr(C)]
#[derive(Debug, Clone, Default)]
pub struct bpf_attr_prog_load {
    /// Program type
    pub prog_type: u32,
    /// Instruction count
    pub insn_cnt: u32,
    /// Instructions pointer
    pub insns: u64,
    /// License string
    pub license: u64,
    /// Log level
    pub log_level: u32,
    /// Log buffer size
    pub log_size: u32,
    /// Log buffer pointer
    pub log_buf: u64,
    /// Kernel version
    pub kern_version: u32,
    /// Program flags
    pub prog_flags: u32,
    /// Program name
    pub prog_name: [u8; 16],
    /// Interface index
    pub prog_ifindex: u32,
    /// Expected attach type
    pub expected_attach_type: u32,
    /// BTF fd
    pub prog_btf_fd: u32,
    /// Function info record size
    pub func_info_rec_size: u32,
    /// Function info pointer
    pub func_info: u64,
    /// Function info count
    pub func_info_cnt: u32,
    /// Line info record size
    pub line_info_rec_size: u32,
    /// Line info pointer
    pub line_info: u64,
    /// Line info count
    pub line_info_cnt: u32,
    /// Attach BTF ID
    pub attach_btf_id: u32,
    /// Attach program fd
    pub attach_prog_fd: u32,
    /// Core relo count
    pub core_relo_cnt: u32,
    /// FD array pointer
    pub fd_array: u64,
    /// Core relos pointer
    pub core_relos: u64,
    /// Core relo record size
    pub core_relo_rec_size: u32,
    /// Log true size
    pub log_true_size: u32,
}

// ============================================================================
// Verifier environment
// ============================================================================

/// BPF verifier log
#[repr(C)]
pub struct bpf_verifier_log {
    /// Log level
    pub level: u32,
    /// Log buffer
    pub kbuf: *mut u8,
    /// Buffer length
    pub len_total: u32,
    /// Current position
    pub len_used: u32,
    /// Start position
    pub start_pos: u32,
    /// End position
    pub end_pos: u32,
    /// User buffer
    pub ubuf: *mut core::ffi::c_char,
}

/// BPF verifier environment
#[repr(C)]
pub struct bpf_verifier_env {
    /// Program being verified
    pub prog: *mut bpf_prog,
    /// Verifier operations
    pub ops: *const bpf_verifier_ops,
    /// Instruction auxiliary data
    pub insn_aux_data: *mut bpf_insn_aux_data,
    /// Current verifier state
    pub cur_state: *mut bpf_verifier_state,
    /// Explored states hash table
    pub explored_states: *mut *mut bpf_verifier_state_list,
    /// Free list
    pub free_list: *mut bpf_verifier_state_list,
    /// Head states
    pub head_states: *mut bpf_verifier_state,
    /// Number of subprograms
    pub subprog_cnt: u32,
    /// Subprogram info array
    pub subprog_info: [bpf_subprog_info; MAX_BPF_SUBPROGS],
    /// Verifier log
    pub log: bpf_verifier_log,
    /// Current instruction index
    pub insn_idx: i32,
    /// Previous instruction index
    pub prev_insn_idx: i32,
    /// Is program privileged
    pub allow_ptr_leaks: bool,
    /// Allow pointer arithmetic
    pub allow_ptr_to_map_access: bool,
    /// Is program for BPF-to-BPF call
    pub bpf_capable: bool,
    /// Can bypass spec mitigation
    pub bypass_spec_v1: bool,
    /// Can bypass spec mitigation v4
    pub bypass_spec_v4: bool,
    /// Whether program is sleepable
    pub insn_processed: u32,
    /// Total states count
    pub total_states: u32,
    /// Peak states count
    pub peak_states: u32,
    /// Previous jumps processed
    pub prev_jmps_processed: u32,
    /// Previous instructions processed
    pub prev_insn_processed: u32,
    /// Jumps processed
    pub jmps_processed: u32,
    /// Maximum states per instruction
    pub max_states_per_insn: u32,
    /// Explored states size
    pub explored_states_size: u32,
    /// Kfunc BTF tab
    pub kfunc_btf_tab: *mut bpf_kfunc_btf_tab,
    /// Used BTFs
    pub used_btfs: [btf_mod_pair; MAX_USED_BTFS],
    /// Used BTF count
    pub used_btf_cnt: u32,
    /// Used maps
    pub used_maps: [*mut bpf_map; 64],
    /// Used map count
    pub used_map_cnt: u32,
    /// Test state frequency
    pub test_state_freq: bool,
}

/// Per-instruction auxiliary data
#[repr(C)]
#[derive(Debug, Clone, Default)]
pub struct bpf_insn_aux_data {
    /// Map pointer state
    pub map_ptr_state: bpf_map_ptr_state,
    /// Map key state
    pub map_key_state: u64,
    /// Prune point
    pub prune_point: bool,
    /// Force checkpoint
    pub force_checkpoint: bool,
    /// JMP point
    pub jmp_point: bool,
    /// Calls callback
    pub calls_callback: bool,
    /// Sanitize stack spill
    pub sanitize_stack_spill: bool,
    /// ALU state for sanitization
    pub alu_state: u8,
    /// Original instruction index
    pub orig_idx: u32,
    /// Nospec
    pub nospec: bool,
    /// Is iter next
    pub is_iter_next: bool,
    /// Call target index
    pub call_imm: i32,
    /// Kfunc BTF ID
    pub kfunc_btf_id: u32,
}

/// Map pointer state
#[repr(C)]
#[derive(Debug, Clone, Copy, Default)]
pub struct bpf_map_ptr_state {
    /// Map pointer
    pub map_ptr: *mut bpf_map,
    /// Is poisoned
    pub poison: bool,
    /// Is unprivileged
    pub unpriv: bool,
}

/// Verifier state
#[repr(C)]
pub struct bpf_verifier_state {
    /// Frame states (call stack)
    pub frame: [*mut bpf_func_state; MAX_CALL_FRAMES as usize],
    /// Current frame index
    pub curframe: u32,
    /// Parent state for pruning
    pub parent: *mut bpf_verifier_state,
    /// Branches remaining
    pub branches: u32,
    /// Number of references
    pub refs_cnt: u32,
    /// References array
    pub refs: *mut bpf_reference_state,
    /// Active locks count
    pub active_locks: u32,
    /// Active RCU lock count
    pub active_rcu_locks: u32,
    /// Active preempt lock count
    pub active_preempt_locks: u32,
    /// Active IRQ ID
    pub active_irq_id: u32,
    /// Is speculative path
    pub speculative: bool,
    /// May goto depth
    pub may_goto_depth: u32,
    /// Callback unroll depth
    pub callback_unroll_depth: u32,
    /// Instruction index
    pub insn_idx: u32,
    /// DFS depth
    pub dfs_depth: u32,
    /// Last instruction index
    pub last_insn_idx: u32,
    /// First instruction index
    pub first_insn_idx: u32,
    /// JMP history count
    pub jmp_history_cnt: u32,
    /// JMP history
    pub jmp_history: *mut bpf_jmp_history_entry,
}

/// Function state (per stack frame)
#[repr(C)]
pub struct bpf_func_state {
    /// Register states
    pub regs: [bpf_reg_state; MAX_BPF_REG],
    /// Call site index
    pub callsite: i32,
    /// Frame number
    pub frameno: u32,
    /// Subprogram index
    pub subprogno: u32,
    /// Async entry count
    pub async_entry_cnt: u32,
    /// In async callback
    pub in_async_callback_fn: bool,
    /// In callback
    pub in_callback_fn: bool,
    /// In exception callback
    pub in_exception_callback_fn: bool,
    /// Allocated stack slots
    pub allocated_stack: i32,
    /// Stack states
    pub stack: *mut bpf_stack_state,
}

/// Register state
#[repr(C)]
#[derive(Clone)]
pub struct bpf_reg_state {
    /// Register type
    pub type_: bpf_reg_type,
    /// Type flags
    pub type_flags: u32,
    /// Signed min value
    pub smin_value: i64,
    /// Signed max value
    pub smax_value: i64,
    /// Unsigned min value
    pub umin_value: u64,
    /// Unsigned max value
    pub umax_value: u64,
    /// 32-bit signed min
    pub s32_min_value: i32,
    /// 32-bit signed max
    pub s32_max_value: i32,
    /// 32-bit unsigned min
    pub u32_min_value: u32,
    /// 32-bit unsigned max
    pub u32_max_value: u32,
    /// Variable offset
    pub var_off: tnum,
    /// Pointer ID
    pub id: u32,
    /// Reference object ID
    pub ref_obj_id: u32,
    /// Map pointer (for PTR_TO_MAP_VALUE)
    pub map_ptr: *mut bpf_map,
    /// BTF pointer (for PTR_TO_BTF_ID)
    pub btf: *mut btf,
    /// BTF ID
    pub btf_id: u32,
    /// Memory size
    pub mem_size: u32,
    /// Dynptr ID
    pub dynptr_id: u32,
    /// Raw mode
    pub raw_mode: bool,
    /// Offset
    pub off: i32,
    /// Pointer is live
    pub live: u32,
    /// Precise tracking
    pub precise: bool,
}

/// Tracked number (tnum)
#[repr(C)]
#[derive(Debug, Clone, Copy, Default)]
pub struct tnum {
    /// Known value bits
    pub value: u64,
    /// Unknown bits mask
    pub mask: u64,
}

/// Stack state
#[repr(C)]
#[derive(Clone, Default)]
pub struct bpf_stack_state {
    /// Spilled register
    pub spilled_ptr: bpf_reg_state,
    /// Slot types (8 slots for 8 bytes)
    pub slot_type: [u8; 8],
}

/// Reference state
#[repr(C)]
#[derive(Debug, Clone, Default)]
pub struct bpf_reference_state {
    /// Reference ID
    pub id: u32,
    /// Instruction index that acquired
    pub insn_idx: u32,
    /// Type (PTR, LOCK, etc.)
    pub type_: u32,
}

/// JMP history entry
#[repr(C)]
#[derive(Debug, Clone, Default)]
pub struct bpf_jmp_history_entry {
    /// Instruction index
    pub idx: u32,
    /// Previous instruction index
    pub prev_idx: u32,
    /// Flags
    pub flags: u32,
    /// Linked registers
    pub linked_regs: u64,
}

/// State list for explored states
#[repr(C)]
pub struct bpf_verifier_state_list {
    /// Verifier state
    pub state: bpf_verifier_state,
    /// Next in list
    pub next: *mut bpf_verifier_state_list,
    /// Hit count
    pub hit_cnt: i32,
    /// Miss count
    pub miss_cnt: i32,
    /// In free list
    pub in_free_list: bool,
}

/// BTF mod pair for used BTFs
#[repr(C)]
#[derive(Debug, Clone, Default)]
pub struct btf_mod_pair {
    /// BTF pointer
    pub btf: *mut btf,
    /// Module pointer
    pub module: *mut core::ffi::c_void,
}

/// Kfunc BTF tab
#[repr(C)]
pub struct bpf_kfunc_btf_tab {
    /// BTFs
    pub btfs: [bpf_kfunc_btf; 256],
    /// Count
    pub cnt: u32,
}

/// Kfunc BTF entry
#[repr(C)]
#[derive(Debug, Clone, Default)]
pub struct bpf_kfunc_btf {
    /// BTF pointer
    pub btf: *mut btf,
    /// Module pointer
    pub module: *mut core::ffi::c_void,
    /// Offset
    pub offset: i16,
}

/// Verifier operations table
#[repr(C)]
pub struct bpf_verifier_ops {
    /// Get function prototype
    pub get_func_proto:
        Option<unsafe extern "C" fn(func_id: i32, prog: *const bpf_prog) -> *const bpf_func_proto>,
    /// Check context access
    pub is_valid_access: Option<
        unsafe extern "C" fn(
            off: i32,
            size: i32,
            access_type: i32,
            prog: *const bpf_prog,
            info: *mut bpf_insn_access_aux,
        ) -> bool,
    >,
    /// Gen prologue
    pub gen_prologue:
        Option<unsafe extern "C" fn(insn: *mut bpf_insn, direct: bool, env: *const bpf_prog) -> i32>,
    /// Gen ld_abs
    pub gen_ld_abs: Option<
        unsafe extern "C" fn(insn: *const bpf_insn, insn_buf: *mut bpf_insn) -> i32,
    >,
    /// Convert context access
    pub convert_ctx_access: Option<
        unsafe extern "C" fn(
            access_type: i32,
            si: *const bpf_insn,
            insn_buf: *mut bpf_insn,
            prog: *const bpf_prog,
            target_size: *mut u32,
        ) -> u32,
    >,
    /// BTF struct access
    pub btf_struct_access: Option<
        unsafe extern "C" fn(
            log: *mut bpf_verifier_log,
            btf: *const btf,
            t: *const btf_type,
            off: i32,
            size: i32,
            atype: i32,
            next_btf_id: *mut u32,
            flag: *mut u32,
            field_name: *mut *const core::ffi::c_char,
        ) -> i32,
    >,
}

/// BPF function prototype
#[repr(C)]
pub struct bpf_func_proto {
    /// Function implementation
    pub func: Option<unsafe extern "C" fn(u64, u64, u64, u64, u64) -> u64>,
    /// GPL only
    pub gpl_only: bool,
    /// Packet access
    pub pkt_access: bool,
    /// Might sleep
    pub might_sleep: bool,
    /// Return type
    pub ret_type: i32,
    /// Argument types
    pub arg_type: [i32; 5],
    /// Argument BTF IDs
    pub arg_btf_id: [*const u32; 5],
    /// Return BTF ID
    pub ret_btf_id: *const u32,
    /// Allowed under callbacks
    pub allowed_under_callbacks: bool,
}

/// Context access auxiliary info
#[repr(C)]
pub struct bpf_insn_access_aux {
    /// Register type for the access
    pub reg_type: bpf_reg_type,
    /// BTF ID if applicable
    pub btf_id: u32,
    /// BTF pointer
    pub btf: *mut btf,
    /// Log for errors
    pub log: *mut bpf_verifier_log,
    /// Context field size
    pub ctx_field_size: u32,
    /// Converted size
    pub converted_op_size: u32,
}

// ============================================================================
// Return value range
// ============================================================================

/// BPF return value range
#[repr(C)]
#[derive(Debug, Clone, Copy, Default)]
pub struct bpf_retval_range {
    /// Minimum value
    pub minval: i32,
    /// Maximum value
    pub maxval: i32,
}

// ============================================================================
// Conversion utilities
// ============================================================================

impl bpf_prog {
    /// Get instructions as a slice
    ///
    /// # Safety
    ///
    /// Caller must ensure that `insns` pointer is valid and points to
    /// at least `len` instructions.
    pub unsafe fn instructions(&self) -> &[bpf_insn] {
        if self.insns.is_null() || self.len == 0 {
            &[]
        } else {
            // SAFETY: Caller guarantees insns is valid for `len` instructions.
            // We checked non-null above. The kernel maintains this invariant.
            core::slice::from_raw_parts(self.insns, self.len as usize)
        }
    }
}

impl bpf_verifier_env {
    /// Get the program being verified
    ///
    /// # Safety
    ///
    /// Caller must ensure the environment is properly initialized.
    pub unsafe fn program(&self) -> Option<&bpf_prog> {
        if self.prog.is_null() {
            None
        } else {
            // SAFETY: Caller guarantees env is properly initialized.
            // We checked non-null above. The kernel sets prog during init.
            Some(&*self.prog)
        }
    }
}

impl Default for bpf_reg_state {
    fn default() -> Self {
        Self {
            type_: bpf_reg_type::NOT_INIT,
            type_flags: 0,
            smin_value: i64::MIN,
            smax_value: i64::MAX,
            umin_value: 0,
            umax_value: u64::MAX,
            s32_min_value: i32::MIN,
            s32_max_value: i32::MAX,
            u32_min_value: 0,
            u32_max_value: u32::MAX,
            var_off: tnum { value: 0, mask: u64::MAX },
            id: 0,
            ref_obj_id: 0,
            map_ptr: core::ptr::null_mut(),
            btf: core::ptr::null_mut(),
            btf_id: 0,
            mem_size: 0,
            dynptr_id: 0,
            raw_mode: false,
            off: 0,
            live: 0,
            precise: false,
        }
    }
}


